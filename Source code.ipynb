{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08882e63",
   "metadata": {},
   "source": [
    "<h1>Graph implementation</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b0e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.edges = []\n",
    "        \n",
    "    def add_edge(self, node, weight):\n",
    "        self.edges.append((node, weight))\n",
    "\n",
    "    def remove_edge(self, node):\n",
    "        for edge in self.edges:\n",
    "            if edge[0] == node:\n",
    "                self.edges.remove(edge)\n",
    "                break\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.vertices = {}\n",
    "        \n",
    "    def add_node(self, node):\n",
    "        self.vertices[node.name] = node\n",
    "        \n",
    "    def add_edge(self, node1, node2, weight):\n",
    "        node1.add_edge(node2, weight)\n",
    "        node2.add_edge(node1, weight)\n",
    "        \n",
    "    def remove_node(self, node):\n",
    "        del self.vertices[node.name]\n",
    "        for vertex in self.vertices.values():\n",
    "            vertex.remove_edge(node)\n",
    "    \n",
    "    def remove_edge(self, node1, node2):\n",
    "        node1.remove_edge(node2)\n",
    "        node2.remove_edge(node1)\n",
    "        \n",
    "    def search(self, item):\n",
    "        for node in self.vertices.values():\n",
    "            if node.name == item:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "# graph = Graph()\n",
    "\n",
    "# a = Node('A')\n",
    "# b = Node('B')\n",
    "# c = Node('C')\n",
    "# d = Node('D')\n",
    "# e = Node('E')\n",
    "# f = Node('F')\n",
    "# g = Node('G')\n",
    "\n",
    "# graph.add_node(a)\n",
    "# graph.add_node(b)\n",
    "# graph.add_node(c)\n",
    "# graph.add_node(d)\n",
    "# graph.add_node(e)\n",
    "# graph.add_node(f)\n",
    "# graph.add_node(g)\n",
    "\n",
    "# graph.add_edge(a, b, 2)\n",
    "# graph.add_edge(a, c, 5)\n",
    "# graph.add_edge(b, c, 6)\n",
    "# graph.add_edge(b, d, 1)\n",
    "# graph.add_edge(b, e, 3)\n",
    "# graph.add_edge(c, f, 8)\n",
    "# graph.add_edge(d, e, 4)\n",
    "# graph.add_edge(e, g, 9)\n",
    "# graph.add_edge(f, g, 7)\n",
    "\n",
    "# for node in graph.vertices.values():\n",
    "#     for edge in node.edges:\n",
    "#         print(f\"{node.name} {edge[0].name} {edge[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddfa635",
   "metadata": {},
   "source": [
    "# Loading graph from a file containing the cities \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a208f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_from_file(filename):\n",
    "    graph = Graph()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            node1, node2, weight = line.strip().split()\n",
    "            if node1 not in graph.vertices:\n",
    "                graph.add_node(Node(node1))\n",
    "            if node2 not in graph.vertices:\n",
    "                graph.add_node(Node(node2))\n",
    "            graph.add_edge(graph.vertices[node1], graph.vertices[node2], int(weight))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2dc040",
   "metadata": {},
   "source": [
    "# BFS Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73a0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, start, end):\n",
    "    queue = [start]\n",
    "    visited = [start]\n",
    "    paths = {start: [start]}\n",
    "\n",
    "    while queue:\n",
    "        vertex = queue.pop(0)\n",
    "        for neighbor in graph.vertices[vertex].edges:\n",
    "            if neighbor[0].name not in visited:\n",
    "                visited.append(neighbor[0].name)\n",
    "                queue.append(neighbor[0].name)\n",
    "                paths[neighbor[0].name] = paths[vertex] + [neighbor[0].name]\n",
    "                if neighbor[0].name == end:\n",
    "                    return paths[end]\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc40328",
   "metadata": {},
   "source": [
    "<h1>Loaded Graph</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa58908",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = load_graph_from_file('cities.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8db130b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfs(graph,\"Zerind\",\"Vaslui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6163b",
   "metadata": {},
   "source": [
    "# DFS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23641b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(graph, start, end):\n",
    "    stack = [start]\n",
    "    visited = [start]\n",
    "    paths = {start: [start]}\n",
    "\n",
    "    while stack:\n",
    "        vertex = stack.pop()\n",
    "        for neighbor in graph.vertices[vertex].edges:\n",
    "            if neighbor[0].name not in visited:\n",
    "                visited.append(neighbor[0].name)\n",
    "                stack.append(neighbor[0].name)\n",
    "                paths[neighbor[0].name] = paths[vertex] + [neighbor[0].name]\n",
    "                if neighbor[0].name == end:\n",
    "                    return paths[end]\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b54fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arad',\n",
       " 'Timisoara',\n",
       " 'Lugoj',\n",
       " 'Mehadia',\n",
       " 'Drobeta',\n",
       " 'Craiova',\n",
       " 'Pitesti',\n",
       " 'Bucharest',\n",
       " 'Fagaras']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs(graph,\"Arad\",\"Fagaras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c967b",
   "metadata": {},
   "source": [
    "<h1>UCS Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dcfb81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "def ucs(graph, start, end):\n",
    "    pq = queue.PriorityQueue()\n",
    "    pq.put((0, [start]))\n",
    "    visited = set()\n",
    "    \n",
    "    while not pq.empty():\n",
    "        (cost, path) = pq.get()\n",
    "        node = path[-1]\n",
    "        if node == end:\n",
    "            return path\n",
    "        if node in visited:\n",
    "            continue\n",
    "        visited.add(node)\n",
    "        for neighbor, weight in graph.vertices[node].edges:\n",
    "            if neighbor.name not in visited:\n",
    "                new_cost = cost + weight\n",
    "                new_path = path + [neighbor.name]\n",
    "                pq.put((new_cost, new_path))\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523e2852",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oradea', 'Sibiu', 'Rimnicu', 'Pitesti', 'Bucharest']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ucs(graph,\"Oradea\",\"Bucharest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc2c3e",
   "metadata": {},
   "source": [
    "<h1>Iterative Deepening Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40301c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_deepening(graph, start, end):\n",
    "    depth = 0\n",
    "    while True:\n",
    "        result = depth_limit_search(graph, start, end, depth)\n",
    "        if result is not None:\n",
    "            return result\n",
    "        depth += 1\n",
    "\n",
    "def depth_limit_search(graph, start, end, depth):\n",
    "    stack = [(start, 0)]\n",
    "    visited = [start]\n",
    "    paths = {start: [start]}\n",
    "\n",
    "    while stack:\n",
    "        vertex, level = stack.pop()\n",
    "        if level <= depth:\n",
    "            for neighbor in graph.vertices[vertex].edges:\n",
    "                if neighbor[0].name not in visited:\n",
    "                    visited.append(neighbor[0].name)\n",
    "                    stack.append((neighbor[0].name, level+1))\n",
    "                    paths[neighbor[0].name] = paths[vertex] + [neighbor[0].name]\n",
    "                    if neighbor[0].name == end:\n",
    "                        return paths[end]\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3895fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arad', 'Sibiu', 'Fagaras', 'Bucharest', 'Urziceni', 'Hirsova', 'Eforie']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterative_deepening(graph,\"Arad\",\"Eforie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d01a8",
   "metadata": {},
   "source": [
    "<h1>Bidirectional Search Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a0198f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_f_s(graph, start, end, visited, paths, queue):\n",
    "    vertex = queue.pop(0)\n",
    "    for neighbor in graph.vertices[vertex].edges:\n",
    "        if neighbor[0].name not in visited:\n",
    "            visited.add(neighbor[0].name)\n",
    "            queue.append(neighbor[0].name)\n",
    "            paths[neighbor[0].name] = paths[vertex] + [neighbor[0].name]\n",
    "            if neighbor[0].name == end:\n",
    "                return paths[end], True\n",
    "    return None, False\n",
    "\n",
    "def bidirectional_bfs(graph, start, end):\n",
    "    start_queue = [start]\n",
    "    start_visited = set([start])\n",
    "    start_paths = {start: [start]}\n",
    "\n",
    "    end_queue = [end]\n",
    "    end_visited = set([end])\n",
    "    end_paths = {end: [end]}\n",
    "\n",
    "    while start_queue and end_queue:\n",
    "        path, found = b_f_s(graph, start, end, start_visited, start_paths, start_queue)\n",
    "        if found:\n",
    "            return path\n",
    "        path, found = b_f_s(graph, end, start, end_visited, end_paths, end_queue)\n",
    "        if found:\n",
    "            return path[::-1]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f258294f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arad', 'Sibiu', 'Fagaras', 'Bucharest', 'Urziceni', 'Hirsova', 'Eforie']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirectional_bfs(graph,\"Arad\",\"Eforie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf81bc",
   "metadata": {},
   "source": [
    "<h1>Heuristic Function</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea7187",
   "metadata": {},
   "source": [
    "<h3>Loading the coordinates(latitude and longitude) of the cities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ccd3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_coordinates(filename):\n",
    "    cities_coordinate = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            city = values[0]\n",
    "            latitude = values[1]\n",
    "            longitude = values[2]\n",
    "            cities_coordinate[city] = (float(latitude), float(longitude))\n",
    "    return cities_coordinate\n",
    "\n",
    "city_coordinates = read_coordinates('coordinates.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54712505",
   "metadata": {},
   "source": [
    "<h3>Geodesic distance calculator using the Haversine fomula </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba43e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def distance(coordinates, city1, city2):\n",
    "    lat1, lon1 = coordinates[city1]\n",
    "    lat2, lon2 = coordinates[city2]\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = 6371 * c #6371 is the raidus of earth\n",
    "    \n",
    "    return distance*0.62137119    #returning the distance in miles(1Km == 0.62137119mile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a8824ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(city, destination):\n",
    "    return distance(city_coordinates, city, destination)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5c4e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261.07177160527914\n"
     ]
    }
   ],
   "source": [
    "print(heuristic(\"Arad\", 'Bucharest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1104fb",
   "metadata": {},
   "source": [
    "<h1>Greedy Search Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d1e66cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "def greedy_search(graph, start, end):\n",
    "    pq = queue.PriorityQueue()\n",
    "    pq.put((0, start))\n",
    "    visited = set()\n",
    "    paths = {start: [start]}\n",
    "\n",
    "\n",
    "    while not pq.empty():\n",
    "        current_cost, current_node = pq.get()\n",
    "        if current_node == end:\n",
    "            return paths[current_node]\n",
    "\n",
    "        if current_node not in visited:\n",
    "            visited.add(current_node)\n",
    "            for neighbor in graph.vertices[current_node].edges:\n",
    "                neighbor_node, edge_cost = neighbor[0].name, neighbor[1]\n",
    "                if neighbor_node not in visited:\n",
    "                    priority = mst_heuristic(neighbor_node, end, graph)\n",
    "                    pq.put((priority, neighbor_node))\n",
    "                    if neighbor_node not in paths:\n",
    "                        paths[neighbor_node] = paths[current_node] + [neighbor_node]\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "fd987e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'C', 'F']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# greedy_search(graph, 'A', 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa2432",
   "metadata": {},
   "source": [
    "<h1>A* Search Implementation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3fa6f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "def aStarSearch(graph, start, end):\n",
    "    pq = queue.PriorityQueue()\n",
    "    pq.put((0 + new_heuristic(graph, start, end), [start]))\n",
    "    visited = set()\n",
    "    \n",
    "    while not pq.empty():\n",
    "        (cost, path) = pq.get()\n",
    "        node = path[-1]\n",
    "        if node == end:\n",
    "            return path\n",
    "        if node in visited:\n",
    "            continue\n",
    "        visited.add(node)\n",
    "        for neighbor, weight in graph.vertices[node].edges:\n",
    "            if neighbor.name not in visited:\n",
    "                new_cost = cost - new_heuristic(graph, start, end) + weight + new_heuristic(graph, neighbor.name, end)\n",
    "                new_path = path + [neighbor.name]\n",
    "                pq.put((new_cost, new_path))\n",
    "    \n",
    "    return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "de7c97d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'E', 'G']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aStarSearch(graph, 'Oradea', 'Eforie')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c235189",
   "metadata": {},
   "source": [
    "<h2>Path cost calculator for evaluation<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "777210e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this find the costs of the paths returned by the algorithms\n",
    "def path_cost_calculator(graph, path):\n",
    "        total_cost = 0\n",
    "        for i in range(len(path)-1):\n",
    "            node1 = graph.vertices[path[i]]\n",
    "            node2 = graph.vertices[path[i+1]]\n",
    "            edge_weight = None\n",
    "            for edge in node1.edges:\n",
    "                if edge[0] == node2:\n",
    "                    edge_weight = edge[1]\n",
    "                    break\n",
    "            total_cost += edge_weight\n",
    "        return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4efb90f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_cost_calculator(graph,['Zerind', 'Oradea', 'Sibiu', 'Fagaras', 'Bucharest', 'Urziceni', 'Vaslui'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ae7ce",
   "metadata": {},
   "source": [
    "<h2>Experiment runner function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210d2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis function can help us run the experiment repeatitively, autonomusly\n",
    "\n",
    "import timeit\n",
    "\n",
    "def algorithm_runner(algorithm, cities, num_runs, graph):\n",
    "  \n",
    "    total_time = 0\n",
    "    city1, city2 = cities[0], cities[1]\n",
    "    time_taken_list = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        time_taken = 0\n",
    "        def inner_func():\n",
    "            nonlocal time_taken\n",
    "            time_taken = algorithm(graph, city1, city2)\n",
    "        \n",
    "        time_taken = timeit.timeit(inner_func, number=1)\n",
    "        time_taken_list.append(round(time_taken, 5))\n",
    "        total_time += round(time_taken, 5)\n",
    "\n",
    "    avg_time = total_time / num_runs\n",
    "    time_taken_list.append(round(avg_time, 5))\n",
    "    \n",
    "    #we added the cost in the time_taken_list, it can easily be identified that the last element is the cost\n",
    "    #and the element next to the last element is the average of the time records in Seconds\n",
    "    path = algorithm(graph, city1, city2)\n",
    "    path_cost = path_cost_calculator(graph, path)\n",
    "    time_taken_list.append(path_cost)\n",
    "    \n",
    "    return time_taken_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93557295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm_runner(greedy_search, ['Zerind', 'Sibiu'], 10, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984bb3f",
   "metadata": {},
   "source": [
    "<h1>A simple Table column writer function </h1>\n",
    "<h4>This simple function uses the python docx lib. and helps us simplify tasks by writing table cells in MS-WORD</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94dabc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx import Document\n",
    "# It takes in input the time_list which contains the results of the 10 experiments and the avg time\n",
    "\n",
    "def table_writer(time_list, docname):\n",
    "    document = Document(docname)\n",
    "    table = document.tables[16]\n",
    "    count = 1\n",
    "    for data in time_list:\n",
    "        table.cell(count, 2).text = str(data)\n",
    "        count += 1\n",
    "        \n",
    "    document.save(docname)\n",
    "\n",
    "##### NOTE: we varied the table indexes manually to fill the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825d6019",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alorithm_runner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Running the Algorithms\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m time_list \u001b[39m=\u001b[39m alorithm_runner(aStarSearch, [\u001b[39m'\u001b[39m\u001b[39mZerind\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTimisoara\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m10\u001b[39m, graph)\n\u001b[0;32m      3\u001b[0m \u001b[39m# table_writer(time_list, 'Report.docx' \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alorithm_runner' is not defined"
     ]
    }
   ],
   "source": [
    "# Running the Algorithms\n",
    "time_list = alorithm_runner(aStarSearch, ['Zerind', 'Timisoara'], 10, graph)\n",
    "# table_writer(time_list, 'Report.docx' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450bbd6",
   "metadata": {},
   "source": [
    "<h1>Random Graph generation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2902c1d",
   "metadata": {},
   "source": [
    "<h2>Creating Erdős–Rényi model graphs with fixed probabilities</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f136014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_random_graph(n, p):\n",
    "    nodes = [Node(chr(i)) for i in range(65, 65 + n)]\n",
    "    \n",
    "    graph = Graph()\n",
    "    for node in nodes:\n",
    "        graph.add_node(node)\n",
    "    # Connect nodes randomly based on probability p\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if random.random() < p:\n",
    "                graph.add_edge(nodes[i], nodes[j], random.randint(1, 10))\n",
    "                #The edge weights are randomly generated between 1 and 10\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531e23a",
   "metadata": {},
   "source": [
    "<h4>Generating 16 different graphs with different probabilty and number of nodes and random edge weights</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = [10, 20, 30, 40]\n",
    "\n",
    "# List of edge probabilities\n",
    "probability_list = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "# Generating 16 random graphs\n",
    "graphList = []\n",
    "\n",
    "for n in node_list:\n",
    "    for p in probability_list:\n",
    "        graphList.append(generate_random_graph(n, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529de2e5",
   "metadata": {},
   "source": [
    "<h4>Randomly selecting 5 nodes and forming pairs between them, resulting in C(5, 2)=10 pairs for each graphs</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6980963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations\n",
    "node_pairs = [] #node_pairs is list of list of tuples\n",
    "\n",
    "for graph in graphList:\n",
    "    nodes = list(graph.vertices.values())\n",
    "    selected_nodes = random.sample(nodes, 5)\n",
    "    # create unique node pairs\n",
    "    pairs = list(combinations(selected_nodes, 2))\n",
    "    node_pairs.append(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f9501",
   "metadata": {},
   "source": [
    "<h4>Validating the pairs generated(cheking if path exists between them)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def validate_pairs(graph_list: List[Graph], node_pairs: List[List[tuple]]) -> List[List[tuple]]:\n",
    "    valid_node_pairs = []\n",
    "    for i, graph_pairs in enumerate(node_pairs):\n",
    "        valid_pairs = []\n",
    "        for pair in graph_pairs:\n",
    "            start_node, end_node = pair\n",
    "            path = bfs(graph_list[i], start_node.name, end_node.name)\n",
    "            if path:\n",
    "                valid_pairs.append(pair)\n",
    "        valid_node_pairs.append(valid_pairs)\n",
    "    return valid_node_pairs\n",
    "valid_node_pairs = validate_pairs(graphList, node_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d57bc1",
   "metadata": {},
   "source": [
    "<h3>Designing new Heuristic function for the randomly generated graphs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b782b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_heuristic(graph, start, end):\n",
    "    \n",
    "    '''\n",
    "    We used dijkstra algorithm to find the shortest path and return the sum of the edges as a heuristic value\n",
    "    and this will never overestimate the actual distance, therefore it is admissible\n",
    "    '''\n",
    "    distances = {node: float('inf') for node in graph.vertices}\n",
    "    distances[start] = 0\n",
    "    visited = set()\n",
    "    paths = {start: [start]}\n",
    "    heap = [(0, start)]\n",
    "\n",
    "    while heap:\n",
    "        current_distance, current_node = heapq.heappop(heap)\n",
    "\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "\n",
    "        for neighbor, distance in graph.vertices[current_node].edges:\n",
    "            total_distance = distances[current_node] + distance\n",
    "            if total_distance < distances[neighbor.name]:\n",
    "                distances[neighbor.name] = total_distance\n",
    "                paths[neighbor.name] = paths[current_node] + [neighbor]\n",
    "                heapq.heappush(heap, (total_distance, neighbor.name))\n",
    "\n",
    "        visited.add(current_node)\n",
    "\n",
    "        if current_node == end:\n",
    "            return distances[end]\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60785cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_list = []\n",
    "for i in range(16):\n",
    "    graph_avg_times = []\n",
    "    times = 0\n",
    "    costs = 0\n",
    "    for pairs in valid_node_pairs[i]:\n",
    "        node1, node2 = pairs\n",
    "        time_taken_list = algorithm_runner(aStarSearch, [node1.name, node2.name], 5, graphList[i])\n",
    "        avg_time = time_taken_list[-2]\n",
    "        path_cost = time_taken_list[-1]\n",
    "        graph_avg_times.append((avg_time, path_cost))\n",
    "    for time, ecost in graph_avg_times:\n",
    "        times += time\n",
    "        costs += ecost\n",
    "    write_list.append(\"{:.2e}\".format(times/len(graph_avg_times)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.35e-04', '3.69e-04', '7.68e-04', '7.70e-04', '9.27e-04', '1.86e-03', '2.46e-03', '5.11e-03', '2.18e-03', '4.89e-03', '7.48e-03', '1.05e-02', '5.72e-03', '1.12e-02', '2.25e-02', '2.66e-02']\n"
     ]
    }
   ],
   "source": [
    "print(write_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_writer(write_list,'Report.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579af06",
   "metadata": {},
   "source": [
    "<h1>Node centrality rankings</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b8ce9",
   "metadata": {},
   "source": [
    "<h1>Degree centrality</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe8537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_centrality(graph):\n",
    "    centrality_scores = {}\n",
    "    for node in graph.vertices.values():\n",
    "        centrality_scores[node.name] = len(node.edges)\n",
    "    return centrality_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d52a7",
   "metadata": {},
   "source": [
    "<h4>Ranker function that returns top ten cities based on their centrality</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(dic):\n",
    "    sorted_values = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_nodes = []\n",
    "    for node, centrality in sorted_values[:10]:\n",
    "        top_nodes.append((node, centrality))\n",
    "    return top_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc6406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sibiu', 4),\n",
       " ('Bucharest', 4),\n",
       " ('Arad', 3),\n",
       " ('Craiova', 3),\n",
       " ('Rimnicu', 3),\n",
       " ('Pitesti', 3),\n",
       " ('Urziceni', 3),\n",
       " ('Oradea', 2),\n",
       " ('Zerind', 2),\n",
       " ('Timisoara', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(degree_centrality(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f333f29",
   "metadata": {},
   "source": [
    "<h1>Closeness Centrality</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "def closeness_centrality(graph):\n",
    "    centrality = {}\n",
    "    for node in graph.vertices.values():\n",
    "        visited = set()\n",
    "        q = queue.Queue()\n",
    "        q.put((node, 0))\n",
    "        visited.add(node)\n",
    "        total_distance = 0\n",
    "        while not q.empty():\n",
    "            curr_node, distance = q.get()\n",
    "            total_distance += distance\n",
    "            for neighbor, weight in curr_node.edges:\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    q.put((neighbor, distance + weight))\n",
    "        centrality[node.name] = (len(visited) - 1) / total_distance if total_distance != 0 else 0\n",
    "    return centrality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4e639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pitesti', 0.0034025787965616047),\n",
       " ('Rimnicu', 0.003269098417068135),\n",
       " ('Bucharest', 0.0031040679627511846),\n",
       " ('Craiova', 0.002935269581337865),\n",
       " ('Sibiu', 0.0028936947913493754),\n",
       " ('Fagaras', 0.0027941176470588237),\n",
       " ('Urziceni', 0.0027937068078223793),\n",
       " ('Drobeta', 0.0024733142410830514),\n",
       " ('Giurgiu', 0.0024544632476424235),\n",
       " ('Arad', 0.002431533145636038)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(closeness_centrality(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744f6c8",
   "metadata": {},
   "source": [
    "<h1>Eigenvector Centrality </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def eigen_vector_centrality(graph, max_iterations=100, tolerance=1.0e-6):\n",
    "    centrality = {node.name: 1.0 for node in graph.vertices.values()}\n",
    "    for _ in range(max_iterations):\n",
    "        previous_centrality = centrality.copy()\n",
    "        for node in graph.vertices.values():\n",
    "            node_centrality = 0.0\n",
    "            for neighbor, weight in node.edges:\n",
    "                node_centrality += previous_centrality[neighbor.name] * weight\n",
    "            centrality[node.name] = node_centrality\n",
    "        norm = math.sqrt(sum(value**2 for value in centrality.values()))\n",
    "        if norm == 0.0:\n",
    "            norm = 1.0\n",
    "        error = sum(abs(centrality[node.name]/norm - previous_centrality[node.name]/norm) for node in graph.vertices.values())\n",
    "        if error < tolerance:\n",
    "            break\n",
    "        for node in graph.vertices.values():\n",
    "            centrality[node.name] /= norm\n",
    "    return centrality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74efdb9",
   "metadata": {},
   "source": [
    "<h1>PageRank Centrality</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c22ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "def pagerank_centrality(graph, damping_factor=0.85, max_iterations=100, convergence_threshold=1e-4):\n",
    "    node_count = len(graph.vertices)\n",
    "    page_rank = {node.name: 1 / node_count for node in graph.vertices.values()}\n",
    "    out_degree = {node.name: len(node.edges) for node in graph.vertices.values()}\n",
    "    in_links = {}\n",
    "    for node in graph.vertices.values():\n",
    "        for neighbor, _ in node.edges:\n",
    "            in_links[neighbor.name] = in_links.get(neighbor.name, []) + [node.name]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        prev_page_rank = page_rank.copy()\n",
    "        delta = 0\n",
    "        for node in graph.vertices.values():\n",
    "            rank_sum = 0\n",
    "            for in_link in in_links.get(node.name, []):\n",
    "                rank_sum += prev_page_rank[in_link] / out_degree[in_link]\n",
    "            page_rank[node.name] = (1 - damping_factor) / node_count + damping_factor * rank_sum\n",
    "            delta += abs(page_rank[node.name] - prev_page_rank[node.name])\n",
    "        if delta < convergence_threshold:\n",
    "            break\n",
    "    \n",
    "    return page_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a84e5",
   "metadata": {},
   "source": [
    "<h1>Betweenness centrality</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e8fd0",
   "metadata": {},
   "source": [
    "<h4>It uses the famous Brandes algorithm to compute betweenness centrality</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73899b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality(graph):\n",
    "    centrality = {node.name: 0 for node in graph.vertices.values()}\n",
    "    for node in graph.vertices.values():\n",
    "        stack = []\n",
    "        predecessors = {node.name: [] for node in graph.vertices.values()}\n",
    "        num_shortest_paths = {node.name: 0 for node in graph.vertices.values()}\n",
    "        distance = {node.name: -1 for node in graph.vertices.values()}\n",
    "        distance[node.name] = 0\n",
    "        num_shortest_paths[node.name] = 1\n",
    "        queue = [node]\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            stack.append(current_node)\n",
    "            for neighbor, weight in current_node.edges:\n",
    "                if distance[neighbor.name] == -1:\n",
    "                    queue.append(neighbor)\n",
    "                    distance[neighbor.name] = distance[current_node.name] + weight\n",
    "                if distance[neighbor.name] == distance[current_node.name] + weight:\n",
    "                    num_shortest_paths[neighbor.name] += num_shortest_paths[current_node.name]\n",
    "                    predecessors[neighbor.name].append(current_node)\n",
    "        credit = {node.name: 1 for node in graph.vertices.values()}\n",
    "        while stack:\n",
    "            current_node = stack.pop()\n",
    "            for predecessor in predecessors[current_node.name]:\n",
    "                credit[predecessor.name] += credit[current_node.name] * num_shortest_paths[predecessor.name] / num_shortest_paths[current_node.name]\n",
    "            if current_node != node:\n",
    "                centrality[current_node.name] += credit[current_node.name]\n",
    "    return centrality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c073e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = []\n",
    "vlist = []\n",
    "for city, val in rank(betweenness_centrality(graph)):\n",
    "    clist.append(city)\n",
    "    vlist.append(round(val, 5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_writer(vlist,'Report.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
